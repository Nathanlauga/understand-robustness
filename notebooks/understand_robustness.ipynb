{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Robustness : Adult Census Income\n",
    "\n",
    "----\n",
    "\n",
    "In this notebook you'll explore the term of \"$\\text{Robustness}$\" for a Machine Learning model. To go into specific we'll see that to have a robust model we need to get :\n",
    "\n",
    "1. A model that is not overfitted or underfitted (bias-variance tradeoff)\n",
    "2. A model that stays coherent when generating new data that are credible and outliers data\n",
    "3. A model that resists to attack\n",
    "\n",
    "This list allows us to go through some specific steps in a Machine Learning project :\n",
    "\n",
    "\n",
    "| Section | Topics                            | Some references |\n",
    "|---------|-----------------------------------|-----------------|\n",
    "| 1.      | Cross validation                  |                 |\n",
    "| 1.      | Train-Test split                  |                 |\n",
    "| 1.      | Bias-Variance tradeoff            |                 |\n",
    "| 2.      | Interpretability                  |                 |\n",
    "| 2.      | Local explanation                 |                 |\n",
    "| 2.      | Generating data to test the model |                 |\n",
    "| 3.      | Differents attacks on a model     |                 |\n",
    "| 3.      | Defending against these attacks   |                 |\n",
    "    \n",
    "\n",
    "For this notebook I choose to use [Adult Census Income dataset](https://www.kaggle.com/uciml/adult-census-income). It's available at the `../data/` directory.\n",
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(root_dir, 'data/adult.csv')\n",
    "\n",
    "data = pd.read_csv(fpath, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       30725 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      30718 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  31978 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is loaded ! Great. \n",
    "\n",
    "So now let's get a quick view of the data. I use [`pandas-profiling`](https://github.com/pandas-profiling/pandas-profiling) package to get a quick insight of the data.\n",
    "\n",
    "## Analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30900</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>436798</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28242</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>225053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17704</th>\n",
       "      <td>56</td>\n",
       "      <td>Private</td>\n",
       "      <td>33323</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23829</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>118792</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>68898</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2444</td>\n",
       "      <td>39</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt     education  education.num  \\\n",
       "30900   23    Private  436798  Some-college             10   \n",
       "28242   30    Private  225053       HS-grad              9   \n",
       "17704   56    Private   33323       HS-grad              9   \n",
       "23829   17    Private  118792          11th              7   \n",
       "52      51  State-gov   68898     Assoc-voc             11   \n",
       "\n",
       "           marital.status         occupation   relationship   race     sex  \\\n",
       "30900  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "28242  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "17704  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "23829       Never-married              Sales      Own-child  White  Female   \n",
       "52               Divorced       Tech-support  Not-in-family  White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "30900             0             0              40  United-States  <=50K  \n",
       "28242             0             0              50  United-States  <=50K  \n",
       "17704             0             0              40  United-States  <=50K  \n",
       "23829             0             0               9  United-States  <=50K  \n",
       "52                0          2444              39  United-States   >50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(data, title=\"Adult Census Income\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c06e03c7764441af6ffb64098fe7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Summarize dataset'), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c8e4d7d5443edb437cf8f81a3f373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Generate report structure'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73534baf397c42729f7da520a9343169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Render HTML'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51550d6751874ade9bdd3b3697266bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Export report to file'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fpath = os.path.join(root_dir, 'notebooks/reports/adult.html')\n",
    "\n",
    "profile.to_file(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
       "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Report available at : [../notebooks/reports/adult.html](../notebooks/reports/adult.html)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown('Report available at : [%s](%s)'%(fpath, fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this report we can see the following informations :\n",
    "\n",
    "- There is 24 dupplicates rows\n",
    "- `workclass` has 1836 (5.6%) missing values\n",
    "- `occupation` has 1843 (5.7%) missing values \n",
    "- `native.country` has 583 (1.8%) missing values \n",
    "- `capital.gain` has 29849 (91.7%) zeros\n",
    "- `capital.loss` has 31042 (95.3%) zeros \n",
    "- our target `income` is not correlated with `fnlwgt`, `race` and `native.country`\n",
    "- `relationship` and `sex` are really correlated\n",
    "- `education.num` is the encoded version of `education`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "So we'll do the following preprocessing tasks :\n",
    "\n",
    "- Drop duplicates rows\n",
    "- Drop useless columns\n",
    "\n",
    "And then for the next tasks we create a `scitkit-learn` pipeline to transform our data with the following steps :\n",
    "\n",
    "- Missing values imputer : most common for categories and median for numeric\n",
    "- OneHotEncoder for categories\n",
    "- StandardScaler to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duppl rows\n",
    "data = data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "data = data.drop(columns=[\n",
    "    'fnlwgt','race','native.country','education','relationship'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23940</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2377</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>60</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21890</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  education.num      marital.status  \\\n",
       "23940   21           Private              9       Never-married   \n",
       "137     21           Private             10  Married-civ-spouse   \n",
       "9833    60  Self-emp-not-inc              9  Married-civ-spouse   \n",
       "21890   17           Private              6       Never-married   \n",
       "16904   39           Private             10            Divorced   \n",
       "\n",
       "            occupation     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "23940    Other-service    Male             0             0              40   \n",
       "137    Exec-managerial    Male             0          2377              48   \n",
       "9833   Exec-managerial    Male             0             0              48   \n",
       "21890   Prof-specialty  Female             0             0              15   \n",
       "16904     Adm-clerical  Female             0             0              45   \n",
       "\n",
       "      income  \n",
       "23940  <=50K  \n",
       "137    <=50K  \n",
       "9833   <=50K  \n",
       "21890  <=50K  \n",
       "16904  <=50K  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the pipeline let's encode our target `income` to 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'income'\n",
    "\n",
    "data[target] = data[target].replace({\n",
    "    '<=50K':0,\n",
    "    '>50K':1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24698\n",
       "1     7839\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['workclass', 'marital.status', 'occupation', 'sex']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = preprocessor.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = preprocessor.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>-1.216148</td>\n",
       "      <td>-0.420679</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25031</th>\n",
       "      <td>0.250367</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>1.423579</td>\n",
       "      <td>-0.420679</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32430</th>\n",
       "      <td>-0.996171</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368</th>\n",
       "      <td>-1.436125</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4    5    6    7    8   \\\n",
       "11806 -1.216148 -0.420679 -0.145975 -0.216743 -0.035664  0.0  0.0  0.0  1.0   \n",
       "25031  0.250367 -0.031815 -0.145975 -0.216743 -0.035664  0.0  0.0  0.0  1.0   \n",
       "28829  1.423579 -0.420679 -0.145975 -0.216743 -0.035664  0.0  0.0  0.0  1.0   \n",
       "32430 -0.996171 -0.031815 -0.145975 -0.216743 -0.035664  0.0  0.0  0.0  1.0   \n",
       "12368 -1.436125 -0.031815 -0.145975 -0.216743 -0.035664  0.0  0.0  0.0  1.0   \n",
       "\n",
       "        9   ...   26   27   28   29   30   31   32   33   34   35  \n",
       "11806  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "25031  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "28829  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "32430  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "12368  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(data_preprocessed).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Robustness : bias-variance tradeoff\n",
    "\n",
    "If you're not familiar with a classic Machine Learning project pipeline, after defining your problem, collect and analyse your data you will need to choose some algorithms to train so that you'll get a model which can predict the task defined at first.\n",
    "\n",
    "Like cooking, training a model need some basic ingredients :\n",
    "- Reliable data : analysed to get the best insight from it and to be sure of its quality\n",
    "- A sample to learn, a sample to validate and a sample to test\n",
    "- An algorithm (or more) that is compatible with your task\n",
    "- A metric (or more) to validate your trained model\n",
    "\n",
    "**Let's assume that our data are reliable for the next part.**\n",
    "\n",
    "The next question before starting the training to ask is the following : \n",
    "\n",
    "    \"Is my dataset representative of the real world ?\"\n",
    "\n",
    "In most cases, training data is extracted from the same source as the future data on which the forecasts will be made. But, imagine you are training an AI that will be able to recognize traffic signs and you use only US traffic signs images, if in reality your algorithm is used in Europe the real data is different from training ! **You need to anticipate if your training data do not miss some possible input in real situation.**\n",
    "\n",
    "Again for our Adult Census income case, let's say that the data is representative.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1. What is a train, validation and test set ?\n",
    "\n",
    "Now how can we ensure our model is robust ?\n",
    "\n",
    "Wikipedia says :\n",
    "\n",
    "    In computer science, robustness is the ability of a computer system to cope with errors during execution \n",
    "    and cope with erroneous input.\n",
    "    \n",
    "<div style=\"text-align:right\"><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Robustness_(computer_science)\">Wikipedia : Robustness (computer science)</a></div>\n",
    "    \n",
    "For the Machine Learning, we can add that :\n",
    "\n",
    "    The robustness is the property that characterizes how effective your algorithm is while being tested \n",
    "    on the new independent (but similar) dataset. In the other words, the robust algorithm is the one, \n",
    "    the testing error of which is close to the training error.\n",
    "    \n",
    "\n",
    "<div style=\"text-align:right\"><a target=\"_blank\" href=\"https://www.researchgate.net/post/What_is_the_definition_of_the_robustness_of_a_machine_learning_algorithm\">ResearchGate : What is the definition of the robustness of a machine learning algorithm?</a></div>\n",
    "\n",
    "And enter the term of **train set** and **test set** (and I add the **validation set**). What are they ?\n",
    "\n",
    "- **Training Dataset**: The sample of data used to fit the model.\n",
    "- **Validation Dataset**: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
    "- **Test Dataset**: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "[About Train, Validation and Test Sets in Machine Learning](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)\n",
    "\n",
    "This picture summarize the concept :    \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img width=\"700\" src=\"https://miro.medium.com/max/1896/1*r73p1rxMZWnZLoYi5Odf4A.png\">\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<strong style=\"color:red\">/!\\ You need to be sure each dataset are representative of the \"real world\" and randomly generated /!\\ </strong> (some tasks don't need random generation like timeseries prediction)\n",
    "\n",
    "\n",
    "## 1.2. Cross validation (K-fold)\n",
    "\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into $k$ equal sized subsamples. Of the $k$ subsamples, a single subsample is retained as the validation data for testing the model, and the remaining $k − 1$ subsamples are used as training data. The cross-validation process is then repeated $k$ times, with each of the $k$ subsamples used exactly once as the validation data. The k results can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once.\n",
    "\n",
    "\n",
    "<div style=\"text-align:right\"><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\">Wikipedia : Cross Validation</a></div>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img width=\"700\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/KfoldCV.gif/1920px-KfoldCV.gif\">\n",
    "\n",
    "Illustration of k-fold cross-validation when n = 12 observations and k = 3. After data is shuffled, a total of 3 models will be trained and tested.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## 1.3. How to split the dataset into train, validation and test ?\n",
    "\n",
    "There is not magic frequency for the split of the training set. But if you have not a lot of data (1000~10000 rows) the rule of 60% train, 20% validation and 20% is recommended.\n",
    "\n",
    "But when you have a lot of data like more than 10 millions, taking 1% as validation and test is more than acceptable.\n",
    "\n",
    "\n",
    "## 1.4. Overfitting & Underfitting\n",
    "\n",
    "**Overfitting** is when your model is specialized on your training set : it works really well on your train set, but it do not generalize well. **When a model overfit, we say that the model has a high variance.**\n",
    "\n",
    "What is variance?\n",
    "\n",
    "    Variance is the variability of model prediction for a given data point or a value which tells us spread \n",
    "    of our data. Model with high variance pays a lot of attention to training data and does not \n",
    "    generalize on the data which it hasn’t seen before. As a result, such models perform very well \n",
    "    on training data but has high error rates on test data.\n",
    "    \n",
    "**Underfitting**  is the case where the model has “ not learned enough” from the training data, resulting in low generalization and unreliable predictions. **When a model underfit, we say that the model has a high bias.**\n",
    "\n",
    "What is bias?\n",
    "\n",
    "    Bias is the difference between the average prediction of our model and the correct value which \n",
    "    we are trying to predict. Model with high bias pays very little attention to the training data \n",
    "    and oversimplifies the model. It always leads to high error on training and test data.\n",
    "    \n",
    "[Understanding the Bias-Variance Tradeoff](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*9hPX9pAO3jqLrzt0IE3JzA.png\">\n",
    "\n",
    "Why is Bias Variance Tradeoff?\n",
    "\n",
    "If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it’s going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data.\n",
    "\n",
    "This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time.\n",
    "\n",
    "--- \n",
    "\n",
    "## In practice : on Adult Census Income\n",
    "\n",
    "Here, I decided to train a **RandomForest** algorithm and to use **accuracy** as the score function.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### train_test_split\n",
    "\n",
    "If your using tabular data, you can use the `train_test_split()` function from `scikit-learn`\n",
    "\n",
    "[Documentation of train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "Using this function allows you to separate train and test randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessor.transform(data)\n",
    "y = data[target]\n",
    "\n",
    "# Spliting train and test set.\n",
    "# Don't forget to specify a random_state to reproduce this operation in the future !\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "X_train shape : (26029, 36)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "X_test shape : (6508, 36)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('X_train shape : %s'%str(X_train.shape)))\n",
    "display(Markdown('X_test shape : %s'%str(X_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train freq\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.757232\n",
       "1    0.242768\n",
       "Name: income, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test freq\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.766441\n",
       "1    0.233559\n",
       "Name: income, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check target freq into train and test\n",
    "print('y_train freq')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "print('y_test freq')\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting example\n",
    "\n",
    "Let's create a Decision Tree that has a `max_depth` of 500 which means overfitting because it'll explore almost all possibilities of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=500, random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 97.16%\n",
      "Test accuracy : 82.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train accuracy : %.2f%%'%(acc_train*100))\n",
    "print('Test accuracy : %.2f%%'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the training score is fat better than the testing one.\n",
    "\n",
    "**To be sure that your model is not overfitted you need to compare train and test score : if the difference is important then your model is overfitted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1, random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 75.72%\n",
      "Test accuracy : 76.64%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train accuracy : %.2f%%'%(acc_train*100))\n",
    "print('Test accuracy : %.2f%%'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the accuracy is very low for both the train set and the test set !\n",
    "\n",
    "\n",
    "**To be sure that your model is not underfitted you need to compare train and test score : if both score are low then your model is underfitted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation with a grid search\n",
    "\n",
    "The module `scikit-learn` offers you some ways to use cross validation. \n",
    "\n",
    "You can use the `GridSearchCV` which tests all combinations with a given list of parameters. Also there is the `RandomizedSearchCV` class that tests random combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [2, 5, 7, 10],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 25, 50, 100]})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'max_depth': [2,5,7,10],\n",
    "    'min_samples_split': [2,5,10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(rf, parameters)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 86.88%\n",
      "Test accuracy : 86.09%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train accuracy : %.2f%%'%(acc_train*100))\n",
    "print('Test accuracy : %.2f%%'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Robustness : reliability of the prediction on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Robustness : resistent to attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustness",
   "language": "python",
   "name": "robustness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
